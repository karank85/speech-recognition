{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karank85/speech-recognition/blob/main/Copy_of_Project_2_Non_DL_Speech_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "joalvPPIEovi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from numpy import ndarray\n",
        "import pandas as pd\n",
        "\n",
        "import librosa\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import librosa.display\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import glob\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "librosa.__version__"
      ],
      "metadata": {
        "id": "0I4Jsfwxqda-",
        "outputId": "36e7b2b1-e204-4fd7-ff90-da948799348a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.10.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "O00x13rfjSEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "oFl-7zCtzEAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assumptions:\n",
        "# - The transcription file is located in the same directory as the audio files.\n",
        "class AudioDataset:\n",
        "  \"\"\"\n",
        "  Class for loading and storing audio data.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self.df = pd.DataFrame(columns=['id', 'path', 'transcription'])\n",
        "\n",
        "  def load_transcriptions(self, directory_path: str) -> bool:\n",
        "    \"\"\"\n",
        "    Load all transcriptions from a given directory, including subdirectories.\n",
        "    Returns False if no transcription files were found, or if any failed to load.\n",
        "    \"\"\"\n",
        "    transcriptions_path = glob.glob(\n",
        "        f\"{directory_path}/**/*.trans.txt\",\n",
        "        recursive=True\n",
        "    )\n",
        "\n",
        "    if len(transcriptions_path) == 0:\n",
        "      return False\n",
        "\n",
        "    for path in transcriptions_path:\n",
        "      if not self.load_transcription_file(path):\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "  def load_transcription_file(self, file_path: str) -> bool:\n",
        "    \"\"\"\n",
        "    Parse transcription file and records the audio ID - subtitle mapping.\n",
        "    Returns False if the file could not be read.\n",
        "    \"\"\"\n",
        "    with open(file_path, \"r\") as file:\n",
        "      file_directory = os.path.dirname(file_path)\n",
        "\n",
        "      lines = file.read().split(\"\\n\")\n",
        "      for line in lines:\n",
        "        if len(line.strip()) == 0:\n",
        "          continue\n",
        "        splitter = line.split(\" \")\n",
        "        file_name = splitter[0]\n",
        "        file_content = ' '.join(splitter[1:])\n",
        "        self.df.loc[len(self.df)] = {\n",
        "            'id':file_name,\n",
        "            'transcription':file_content,\n",
        "            'path': f'{file_directory}/{file_name}.flac'\n",
        "        }\n",
        "      return True\n",
        "    return False\n",
        "\n",
        "  def keys(self):\n",
        "    return iter(self.df['id'])\n",
        "\n",
        "  def get(self, id: int):\n",
        "    \"\"\"\n",
        "    Retrieve a dataframe row from ID.\n",
        "    \"\"\"\n",
        "    return self.df.loc[self.df['id'] == id]"
      ],
      "metadata": {
        "id": "q56S9PXxTVx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = AudioDataset()"
      ],
      "metadata": {
        "id": "KSEEVPAvV1IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.load_transcriptions(\"/content/drive/MyDrive/test_run_dataset\")"
      ],
      "metadata": {
        "id": "ZKy7iv3DWBZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting Features"
      ],
      "metadata": {
        "id": "vUEkvJCdpukC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from librosa.feature import mfcc\n",
        "import librosa\n",
        "audio, sampling_freq = librosa.load(ds.df.head()['path'].values[0])\n",
        "mfcc_features = librosa.feature.mfcc(sr=sampling_freq, y=audio)\n",
        "print('\\nNumber of windows =', mfcc_features.shape[0])\n",
        "print('Length of each feature =', mfcc_features.shape[1])"
      ],
      "metadata": {
        "id": "Xn_bykkYrAsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc_features = mfcc_features.T\n",
        "plt.matshow(mfcc_features)\n",
        "plt.title('MFCC')"
      ],
      "metadata": {
        "id": "K6xerVMEP_U2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hmmlearn\n",
        "!pip install features"
      ],
      "metadata": {
        "id": "B9BvQpBmmA-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "from hmmlearn import hmm #importing GaussianHMM\n",
        "import librosa # reading wavefilesfrom librosa.feature import mfcc #to extract mfcc features"
      ],
      "metadata": {
        "id": "_H-mpoRAmDd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HMMTrainer(object):\n",
        "  def __init__(self, model_name='GaussianHMM', n_components=4):\n",
        "     self.model_name = model_name\n",
        "     self.n_components = n_components\n",
        "\n",
        "     self.models = []\n",
        "     if self.model_name == 'GaussianHMM':\n",
        "        self.model=hmm.GaussianHMM(n_components=4)\n",
        "     else:\n",
        "        print(\"Please choose GaussianHMM\")\n",
        "\n",
        "  def train(self, X):\n",
        "      self.models.append(self.model.fit(X))\n",
        "\n",
        "  def get_score(self, input_data):\n",
        "      return self.model.score(input_data)"
      ],
      "metadata": {
        "id": "e9pLjDWuQtqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.df"
      ],
      "metadata": {
        "id": "CiK6LEbOoBfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hmm_models = []\n",
        "X = np.array([])\n",
        "y_words = []\n",
        "label = []\n",
        "\n",
        "for index, row in ds.df.iloc[:-1, :].iterrows():\n",
        "   # Read the input file\n",
        "   audio, sampling_freq = librosa.load(row['path'])\n",
        "   # Extract MFCC features\n",
        "   mfcc_features = librosa.feature.mfcc(sr=sampling_freq, y=audio)\n",
        "   # Append to the variable X\n",
        "   if len(X) == 0:\n",
        "     X = mfcc_features[:, :15]  # 15 here denotes the number of MFCC coefficients to consider\n",
        "   else:\n",
        "     X = np.append(X, mfcc_features[:, :15], axis=0)\n",
        "   # Append the label\n",
        "   y_words.append(row['transcription'])\n",
        "  #  print('X.shape =', X.shape)\n",
        "\n",
        "   # Train HMM model for this iteration\n",
        "   hmm_trainer = HMMTrainer()\n",
        "   hmm_trainer.train(X)  # Train using the current MFCC features\n",
        "   hmm_models.append((hmm_trainer, row['transcription']))\n"
      ],
      "metadata": {
        "id": "oTVddhw_yy7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = ds.df.iloc[-1,:]\n",
        "# Read the input file\n",
        "audio, sampling_freq = librosa.load(test['path'])\n",
        "# Extract MFCC features\n",
        "mfcc_features = librosa.feature.mfcc(sr=sampling_freq, y=audio)\n",
        "X = mfcc_features[:, :15]\n",
        "y_word = test['transcription']"
      ],
      "metadata": {
        "id": "YYhzPXAKSktn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "for hmm_model, _ in hmm_models:\n",
        "    score = hmm_model.get_score(X)\n",
        "    scores.append(score)\n",
        "\n",
        "print(scores)\n",
        "index = np.array(scores).argmax()\n",
        "# Print the output\n",
        "print(\"\\nTrue:\", y_word)\n",
        "\n",
        "print(\"Predicted:\", hmm_models[index][1])"
      ],
      "metadata": {
        "id": "haeYhQDoSKd8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}