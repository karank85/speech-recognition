{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karank85/speech-recognition/blob/main/Copy_of_Project_2_Non_DL_Speech_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "joalvPPIEovi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from numpy import ndarray\n",
        "import pandas as pd\n",
        "\n",
        "import librosa\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import librosa.display\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import glob\n",
        "import torch\n",
        "\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0I4Jsfwxqda-",
        "outputId": "91b81642-070e-49cf-d310-5571bbfbbd13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.10.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "librosa.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O00x13rfjSEp",
        "outputId": "b3cc03e9-24c3-4424-a5e8-6bac7c56b36a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "oFl-7zCtzEAS",
        "outputId": "1a3ec422-a081-42ce-b438-7ac377bdff8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "q56S9PXxTVx3"
      },
      "outputs": [],
      "source": [
        "# # Assumptions:\n",
        "# # - The transcription file is located in the same directory as the audio files.\n",
        "# class AudioDataset:\n",
        "#   \"\"\"\n",
        "#   Class for loading and storing audio data.\n",
        "#   \"\"\"\n",
        "\n",
        "#   def __init__(self):\n",
        "#     self.df = pd.DataFrame(columns=['id', 'path', 'transcription'])\n",
        "\n",
        "#   def load_transcriptions(self, directory_path: str) -> bool:\n",
        "#     \"\"\"\n",
        "#     Load all transcriptions from a given directory, including subdirectories.\n",
        "#     Returns False if no transcription files were found, or if any failed to load.\n",
        "#     \"\"\"\n",
        "#     transcriptions_path = glob.glob(\n",
        "#         f\"{directory_path}/**/*.trans.txt\",\n",
        "#         recursive=True\n",
        "#     )\n",
        "\n",
        "#     if len(transcriptions_path) == 0:\n",
        "#       return False\n",
        "\n",
        "#     for path in transcriptions_path:\n",
        "#       if not self.load_transcription_file(path):\n",
        "#         return False\n",
        "\n",
        "#     return True\n",
        "\n",
        "\n",
        "\n",
        "#   def load_transcription_file(self, file_path: str) -> bool:\n",
        "#     \"\"\"\n",
        "#     Parse transcription file and records the audio ID - subtitle mapping.\n",
        "#     Returns False if the file could not be read.\n",
        "#     \"\"\"\n",
        "#     with open(file_path, \"r\") as file:\n",
        "#       file_directory = os.path.dirname(file_path)\n",
        "\n",
        "#       lines = file.read().split(\"\\n\")\n",
        "#       for line in lines:\n",
        "#         if len(line.strip()) == 0:\n",
        "#           continue\n",
        "#         splitter = line.split(\" \")\n",
        "#         file_name = splitter[0]\n",
        "#         file_content = ' '.join(splitter[1:])\n",
        "#         self.df.loc[len(self.df)] = {\n",
        "#             'id':file_name,\n",
        "#             'transcription':file_content,\n",
        "#             'path': f'{file_directory}/{file_name}.flac'\n",
        "#         }\n",
        "#       return True\n",
        "#     return False\n",
        "\n",
        "#   def keys(self):\n",
        "#     return iter(self.df['id'])\n",
        "\n",
        "#   def get(self, id: int):\n",
        "#     \"\"\"\n",
        "#     Retrieve a dataframe row from ID.\n",
        "#     \"\"\"\n",
        "#     return self.df.loc[self.df['id'] == id]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assumptions:\n",
        "# - The transcription file is located in the same directory as the audio files.\n",
        "class AudioDataset:\n",
        "  \"\"\"\n",
        "  Class for loading and storing audio data.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self.df = pd.DataFrame(columns=['id', 'path', 'transcription'])\n",
        "\n",
        "  def load_transcriptions(self, directory_path: str) -> bool:\n",
        "    \"\"\"\n",
        "    Load all transcriptions from a given directory, including subdirectories.\n",
        "    Returns False if no transcription files were found, or if any failed to load.\n",
        "    \"\"\"\n",
        "    sound_names = glob.glob(\n",
        "        f\"{directory_path}/**/*.wav\",\n",
        "        recursive=True\n",
        "    )\n",
        "\n",
        "    if len(sound_names) == 0:\n",
        "      return False\n",
        "\n",
        "    for path in sound_names:\n",
        "      if not self.load_transcription_file(path):\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "  def load_transcription_file(self, file_path: str) -> bool:\n",
        "    \"\"\"\n",
        "    Parse transcription file and records the audio ID - subtitle mapping.\n",
        "    Returns False if the file could not be read.\n",
        "    \"\"\"\n",
        "\n",
        "    file_directory = Path(file_path).parent\n",
        "    file_name = Path(file_path).stem\n",
        "    self.df.loc[len(self.df)] = {\n",
        "        'id':file_name,\n",
        "        'transcription':file_directory.name,\n",
        "        'path': f'{file_directory}/{file_name}.wav'\n",
        "    }\n",
        "    return True\n",
        "\n",
        "  def keys(self):\n",
        "    return iter(self.df['id'])\n",
        "\n",
        "  def get(self, id: int):\n",
        "    \"\"\"\n",
        "    Retrieve a dataframe row from ID.\n",
        "    \"\"\"\n",
        "    return self.df.loc[self.df['id'] == id]"
      ],
      "metadata": {
        "id": "s5MsALQX_47K"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dict = {}"
      ],
      "metadata": {
        "id": "5yKBHPxjqa8_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "KSEEVPAvV1IW"
      },
      "outputs": [],
      "source": [
        "# ds = AudioDataset()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_subdirectories = glob.glob(\n",
        "        f\"/content/drive/MyDrive/test_hmm/*/\",\n",
        "        recursive=True\n",
        ")\n",
        "\n",
        "for path in all_subdirectories:\n",
        "  fruit_label = Path(path).name\n",
        "  ds = AudioDataset()\n",
        "  if ds.load_transcriptions(path):\n",
        "    df_dict[fruit_label] = ds.df"
      ],
      "metadata": {
        "id": "dVwBCsJEqj8f"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKy7iv3DWBZY",
        "outputId": "f7b96848-56d5-4e3f-d17d-d80513fa1f8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'apple':          id                                               path transcription\n",
              " 0   apple04  /content/drive/MyDrive/test_hmm/apple/apple04.wav         apple\n",
              " 1   apple08  /content/drive/MyDrive/test_hmm/apple/apple08.wav         apple\n",
              " 2   apple15  /content/drive/MyDrive/test_hmm/apple/apple15.wav         apple\n",
              " 3   apple14  /content/drive/MyDrive/test_hmm/apple/apple14.wav         apple\n",
              " 4   apple12  /content/drive/MyDrive/test_hmm/apple/apple12.wav         apple\n",
              " 5   apple10  /content/drive/MyDrive/test_hmm/apple/apple10.wav         apple\n",
              " 6   apple05  /content/drive/MyDrive/test_hmm/apple/apple05.wav         apple\n",
              " 7   apple11  /content/drive/MyDrive/test_hmm/apple/apple11.wav         apple\n",
              " 8   apple09  /content/drive/MyDrive/test_hmm/apple/apple09.wav         apple\n",
              " 9   apple02  /content/drive/MyDrive/test_hmm/apple/apple02.wav         apple\n",
              " 10  apple07  /content/drive/MyDrive/test_hmm/apple/apple07.wav         apple\n",
              " 11  apple06  /content/drive/MyDrive/test_hmm/apple/apple06.wav         apple\n",
              " 12  apple03  /content/drive/MyDrive/test_hmm/apple/apple03.wav         apple\n",
              " 13  apple13  /content/drive/MyDrive/test_hmm/apple/apple13.wav         apple\n",
              " 14  apple01  /content/drive/MyDrive/test_hmm/apple/apple01.wav         apple,\n",
              " 'banana':           id                                               path transcription\n",
              " 0   banana03  /content/drive/MyDrive/test_hmm/banana/banana0...        banana\n",
              " 1   banana06  /content/drive/MyDrive/test_hmm/banana/banana0...        banana\n",
              " 2   banana08  /content/drive/MyDrive/test_hmm/banana/banana0...        banana\n",
              " 3   banana12  /content/drive/MyDrive/test_hmm/banana/banana1...        banana\n",
              " 4   banana07  /content/drive/MyDrive/test_hmm/banana/banana0...        banana\n",
              " 5   banana14  /content/drive/MyDrive/test_hmm/banana/banana1...        banana\n",
              " 6   banana10  /content/drive/MyDrive/test_hmm/banana/banana1...        banana\n",
              " 7   banana01  /content/drive/MyDrive/test_hmm/banana/banana0...        banana\n",
              " 8   banana04  /content/drive/MyDrive/test_hmm/banana/banana0...        banana\n",
              " 9   banana15  /content/drive/MyDrive/test_hmm/banana/banana1...        banana\n",
              " 10  banana02  /content/drive/MyDrive/test_hmm/banana/banana0...        banana\n",
              " 11  banana11  /content/drive/MyDrive/test_hmm/banana/banana1...        banana\n",
              " 12  banana09  /content/drive/MyDrive/test_hmm/banana/banana0...        banana\n",
              " 13  banana05  /content/drive/MyDrive/test_hmm/banana/banana0...        banana\n",
              " 14  banana13  /content/drive/MyDrive/test_hmm/banana/banana1...        banana,\n",
              " 'lime':         id                                             path transcription\n",
              " 0   lime06  /content/drive/MyDrive/test_hmm/lime/lime06.wav          lime\n",
              " 1   lime02  /content/drive/MyDrive/test_hmm/lime/lime02.wav          lime\n",
              " 2   lime04  /content/drive/MyDrive/test_hmm/lime/lime04.wav          lime\n",
              " 3   lime05  /content/drive/MyDrive/test_hmm/lime/lime05.wav          lime\n",
              " 4   lime14  /content/drive/MyDrive/test_hmm/lime/lime14.wav          lime\n",
              " 5   lime12  /content/drive/MyDrive/test_hmm/lime/lime12.wav          lime\n",
              " 6   lime10  /content/drive/MyDrive/test_hmm/lime/lime10.wav          lime\n",
              " 7   lime03  /content/drive/MyDrive/test_hmm/lime/lime03.wav          lime\n",
              " 8   lime07  /content/drive/MyDrive/test_hmm/lime/lime07.wav          lime\n",
              " 9   lime11  /content/drive/MyDrive/test_hmm/lime/lime11.wav          lime\n",
              " 10  lime13  /content/drive/MyDrive/test_hmm/lime/lime13.wav          lime\n",
              " 11  lime15  /content/drive/MyDrive/test_hmm/lime/lime15.wav          lime\n",
              " 12  lime08  /content/drive/MyDrive/test_hmm/lime/lime08.wav          lime\n",
              " 13  lime01  /content/drive/MyDrive/test_hmm/lime/lime01.wav          lime\n",
              " 14  lime09  /content/drive/MyDrive/test_hmm/lime/lime09.wav          lime,\n",
              " 'orange':           id                                               path transcription\n",
              " 0   orange05  /content/drive/MyDrive/test_hmm/orange/orange0...        orange\n",
              " 1   orange10  /content/drive/MyDrive/test_hmm/orange/orange1...        orange\n",
              " 2   orange12  /content/drive/MyDrive/test_hmm/orange/orange1...        orange\n",
              " 3   orange08  /content/drive/MyDrive/test_hmm/orange/orange0...        orange\n",
              " 4   orange04  /content/drive/MyDrive/test_hmm/orange/orange0...        orange\n",
              " 5   orange14  /content/drive/MyDrive/test_hmm/orange/orange1...        orange\n",
              " 6   orange15  /content/drive/MyDrive/test_hmm/orange/orange1...        orange\n",
              " 7   orange06  /content/drive/MyDrive/test_hmm/orange/orange0...        orange\n",
              " 8   orange11  /content/drive/MyDrive/test_hmm/orange/orange1...        orange\n",
              " 9   orange13  /content/drive/MyDrive/test_hmm/orange/orange1...        orange\n",
              " 10  orange03  /content/drive/MyDrive/test_hmm/orange/orange0...        orange\n",
              " 11  orange09  /content/drive/MyDrive/test_hmm/orange/orange0...        orange\n",
              " 12  orange02  /content/drive/MyDrive/test_hmm/orange/orange0...        orange\n",
              " 13  orange07  /content/drive/MyDrive/test_hmm/orange/orange0...        orange\n",
              " 14  orange01  /content/drive/MyDrive/test_hmm/orange/orange0...        orange,\n",
              " 'kiwi':         id                                             path transcription\n",
              " 0   kiwi01  /content/drive/MyDrive/test_hmm/kiwi/kiwi01.wav          kiwi\n",
              " 1   kiwi11  /content/drive/MyDrive/test_hmm/kiwi/kiwi11.wav          kiwi\n",
              " 2   kiwi03  /content/drive/MyDrive/test_hmm/kiwi/kiwi03.wav          kiwi\n",
              " 3   kiwi09  /content/drive/MyDrive/test_hmm/kiwi/kiwi09.wav          kiwi\n",
              " 4   kiwi07  /content/drive/MyDrive/test_hmm/kiwi/kiwi07.wav          kiwi\n",
              " 5   kiwi05  /content/drive/MyDrive/test_hmm/kiwi/kiwi05.wav          kiwi\n",
              " 6   kiwi10  /content/drive/MyDrive/test_hmm/kiwi/kiwi10.wav          kiwi\n",
              " 7   kiwi15  /content/drive/MyDrive/test_hmm/kiwi/kiwi15.wav          kiwi\n",
              " 8   kiwi14  /content/drive/MyDrive/test_hmm/kiwi/kiwi14.wav          kiwi\n",
              " 9   kiwi04  /content/drive/MyDrive/test_hmm/kiwi/kiwi04.wav          kiwi\n",
              " 10  kiwi08  /content/drive/MyDrive/test_hmm/kiwi/kiwi08.wav          kiwi\n",
              " 11  kiwi12  /content/drive/MyDrive/test_hmm/kiwi/kiwi12.wav          kiwi\n",
              " 12  kiwi06  /content/drive/MyDrive/test_hmm/kiwi/kiwi06.wav          kiwi\n",
              " 13  kiwi13  /content/drive/MyDrive/test_hmm/kiwi/kiwi13.wav          kiwi\n",
              " 14  kiwi02  /content/drive/MyDrive/test_hmm/kiwi/kiwi02.wav          kiwi,\n",
              " 'pineapple':              id                                               path  \\\n",
              " 0   pineapple02  /content/drive/MyDrive/test_hmm/pineapple/pine...   \n",
              " 1   pineapple08  /content/drive/MyDrive/test_hmm/pineapple/pine...   \n",
              " 2   pineapple04  /content/drive/MyDrive/test_hmm/pineapple/pine...   \n",
              " 3   pineapple11  /content/drive/MyDrive/test_hmm/pineapple/pine...   \n",
              " 4   pineapple09  /content/drive/MyDrive/test_hmm/pineapple/pine...   \n",
              " 5   pineapple14  /content/drive/MyDrive/test_hmm/pineapple/pine...   \n",
              " 6   pineapple15  /content/drive/MyDrive/test_hmm/pineapple/pine...   \n",
              " 7   pineapple01  /content/drive/MyDrive/test_hmm/pineapple/pine...   \n",
              " 8   pineapple10  /content/drive/MyDrive/test_hmm/pineapple/pine...   \n",
              " 9   pineapple03  /content/drive/MyDrive/test_hmm/pineapple/pine...   \n",
              " 10  pineapple12  /content/drive/MyDrive/test_hmm/pineapple/pine...   \n",
              " 11  pineapple05  /content/drive/MyDrive/test_hmm/pineapple/pine...   \n",
              " 12  pineapple06  /content/drive/MyDrive/test_hmm/pineapple/pine...   \n",
              " 13  pineapple13  /content/drive/MyDrive/test_hmm/pineapple/pine...   \n",
              " 14  pineapple07  /content/drive/MyDrive/test_hmm/pineapple/pine...   \n",
              " \n",
              "    transcription  \n",
              " 0      pineapple  \n",
              " 1      pineapple  \n",
              " 2      pineapple  \n",
              " 3      pineapple  \n",
              " 4      pineapple  \n",
              " 5      pineapple  \n",
              " 6      pineapple  \n",
              " 7      pineapple  \n",
              " 8      pineapple  \n",
              " 9      pineapple  \n",
              " 10     pineapple  \n",
              " 11     pineapple  \n",
              " 12     pineapple  \n",
              " 13     pineapple  \n",
              " 14     pineapple  ,\n",
              " 'peach':          id                                               path transcription\n",
              " 0   peach05  /content/drive/MyDrive/test_hmm/peach/peach05.wav         peach\n",
              " 1   peach12  /content/drive/MyDrive/test_hmm/peach/peach12.wav         peach\n",
              " 2   peach01  /content/drive/MyDrive/test_hmm/peach/peach01.wav         peach\n",
              " 3   peach14  /content/drive/MyDrive/test_hmm/peach/peach14.wav         peach\n",
              " 4   peach15  /content/drive/MyDrive/test_hmm/peach/peach15.wav         peach\n",
              " 5   peach08  /content/drive/MyDrive/test_hmm/peach/peach08.wav         peach\n",
              " 6   peach06  /content/drive/MyDrive/test_hmm/peach/peach06.wav         peach\n",
              " 7   peach07  /content/drive/MyDrive/test_hmm/peach/peach07.wav         peach\n",
              " 8   peach04  /content/drive/MyDrive/test_hmm/peach/peach04.wav         peach\n",
              " 9   peach13  /content/drive/MyDrive/test_hmm/peach/peach13.wav         peach\n",
              " 10  peach02  /content/drive/MyDrive/test_hmm/peach/peach02.wav         peach\n",
              " 11  peach09  /content/drive/MyDrive/test_hmm/peach/peach09.wav         peach\n",
              " 12  peach11  /content/drive/MyDrive/test_hmm/peach/peach11.wav         peach\n",
              " 13  peach10  /content/drive/MyDrive/test_hmm/peach/peach10.wav         peach\n",
              " 14  peach03  /content/drive/MyDrive/test_hmm/peach/peach03.wav         peach}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "df_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUEkvJCdpukC"
      },
      "source": [
        "### Extracting Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Xn_bykkYrAsW"
      },
      "outputs": [],
      "source": [
        "# from librosa.feature import mfcc\n",
        "# import librosa\n",
        "# audio, sampling_freq = librosa.load(ds.df.head()['path'].values[0])\n",
        "# mfcc_features = librosa.feature.mfcc(sr=sampling_freq, y=audio)\n",
        "# print('\\nNumber of windows =', mfcc_features.shape[0])\n",
        "# print('Length of each feature =', mfcc_features.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "K6xerVMEP_U2"
      },
      "outputs": [],
      "source": [
        "# mfcc_features = mfcc_features.T\n",
        "# plt.matshow(mfcc_features)\n",
        "# plt.title('MFCC')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9BvQpBmmA-_",
        "outputId": "ca487b54-12d1-417f-fe95-21ceef148ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hmmlearn in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.3.0)\n",
            "Requirement already satisfied: features in /usr/local/lib/python3.10/dist-packages (0.5.12)\n",
            "Requirement already satisfied: concepts~=0.7 in /usr/local/lib/python3.10/dist-packages (from features) (0.9.2)\n",
            "Requirement already satisfied: fileconfig~=0.5 in /usr/local/lib/python3.10/dist-packages (from features) (0.6.1)\n",
            "Requirement already satisfied: graphviz~=0.7 in /usr/local/lib/python3.10/dist-packages (from features) (0.20.2)\n",
            "Requirement already satisfied: bitsets~=0.7 in /usr/local/lib/python3.10/dist-packages (from concepts~=0.7->features) (0.8.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install hmmlearn\n",
        "!pip install features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "_H-mpoRAmDd6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "from hmmlearn import hmm #importing GaussianHMM\n",
        "import librosa # reading wavefilesfrom librosa.feature import mfcc #to extract mfcc features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "e9pLjDWuQtqI"
      },
      "outputs": [],
      "source": [
        "class HMMTrainer(object):\n",
        "  def __init__(self, model_name='GaussianHMM', n_components=4):\n",
        "     self.model_name = model_name\n",
        "     self.n_components = n_components\n",
        "\n",
        "     self.models = []\n",
        "     if self.model_name == 'GaussianHMM':\n",
        "        self.model=hmm.GaussianHMM(n_components=4)\n",
        "     else:\n",
        "        print(\"Please choose GaussianHMM\")\n",
        "\n",
        "  def train(self, X):\n",
        "      self.models.append(self.model.fit(X))\n",
        "\n",
        "  def get_score(self, input_data):\n",
        "      return self.model.score(input_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "CiK6LEbOoBfQ"
      },
      "outputs": [],
      "source": [
        "# ds.df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hmm_models = []\n",
        "\n",
        "for df in df_dict.items():\n",
        "  fruit_label = df[0]\n",
        "  X = np.array([])\n",
        "  for index, row in df[1].iloc[:-1,:].iterrows():\n",
        "    # Read the input file\n",
        "    audio, sampling_freq = librosa.load(row['path'])\n",
        "    # Extract MFCC features\n",
        "    mfcc_features = librosa.feature.mfcc(sr=sampling_freq, y=audio)\n",
        "    # Append to the variable X\n",
        "    if len(X) == 0:\n",
        "      X = mfcc_features[:, :15]  # 15 here denotes the number of MFCC coefficients to consider\n",
        "    else:\n",
        "      X = np.append(X, mfcc_features[:, :15], axis=0)\n",
        "    # Append the label\n",
        "    # print('X.shape =', X.shape)\n",
        "\n",
        "  # Train HMM model for this iteration\n",
        "  hmm_trainer = HMMTrainer()\n",
        "  hmm_trainer.train(X)  # Train using the current MFCC features\n",
        "  hmm_models.append((hmm_trainer, fruit_label))\n"
      ],
      "metadata": {
        "id": "sd7pFP7Bs5i0"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(hmm_models))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE3dUaKwuQEZ",
        "outputId": "9283dc83-096c-4409-d9a7-014502a2c269"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_files = {}\n",
        "\n",
        "for df in df_dict.items():\n",
        "  truth_label = df[0]\n",
        "  selected_test = df[1].iloc[-1,:]\n",
        "  test_files[truth_label] = selected_test['path']"
      ],
      "metadata": {
        "id": "Ye6wJvkau7wf"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edSWkOzbvXXZ",
        "outputId": "ee5b811f-ad49-4135-ba6e-51425ac9dafc"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'apple': '/content/drive/MyDrive/test_hmm/apple/apple01.wav', 'banana': '/content/drive/MyDrive/test_hmm/banana/banana13.wav', 'lime': '/content/drive/MyDrive/test_hmm/lime/lime09.wav', 'orange': '/content/drive/MyDrive/test_hmm/orange/orange01.wav', 'kiwi': '/content/drive/MyDrive/test_hmm/kiwi/kiwi02.wav', 'pineapple': '/content/drive/MyDrive/test_hmm/pineapple/pineapple07.wav', 'peach': '/content/drive/MyDrive/test_hmm/peach/peach03.wav'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for truth_label, path in test_files.items():\n",
        "  audio, sampling_freq = librosa.load(path)\n",
        "  # Extract MFCC features\n",
        "  mfcc_features = librosa.feature.mfcc(sr=sampling_freq, y=audio)\n",
        "  X = mfcc_features[:, :15]\n",
        "  scores = []\n",
        "  for hmm_model, label in hmm_models:\n",
        "    score = hmm_model.get_score(X)\n",
        "    scores.append(score)\n",
        "  index = np.array(scores).argmax()\n",
        "  # Print the output\n",
        "  print(\"\\nTrue:\", truth_label)\n",
        "  print(\"Predicted:\", hmm_models[index][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn0DxbNAva6g",
        "outputId": "88ab6abb-8f08-4752-ef2b-59e683ed2c2c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "True: apple\n",
            "Predicted: apple\n",
            "\n",
            "True: banana\n",
            "Predicted: banana\n",
            "\n",
            "True: lime\n",
            "Predicted: lime\n",
            "\n",
            "True: orange\n",
            "Predicted: apple\n",
            "\n",
            "True: kiwi\n",
            "Predicted: kiwi\n",
            "\n",
            "True: pineapple\n",
            "Predicted: pineapple\n",
            "\n",
            "True: peach\n",
            "Predicted: peach\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "oTVddhw_yy7B"
      },
      "outputs": [],
      "source": [
        "# hmm_models = []\n",
        "# X = np.array([])\n",
        "\n",
        "# for index, row in ds.df.iterrows():\n",
        "#    # Read the input file\n",
        "#    audio, sampling_freq = librosa.load(row['path'])\n",
        "#    # Extract MFCC features\n",
        "#    mfcc_features = librosa.feature.mfcc(sr=sampling_freq, y=audio)\n",
        "#    # Append to the variable X\n",
        "#    if len(X) == 0:\n",
        "#      X = mfcc_features[:, :15]  # 15 here denotes the number of MFCC coefficients to consider\n",
        "#    else:\n",
        "#      X = np.append(X, mfcc_features[:, :15], axis=0)\n",
        "#    # Append the label\n",
        "#   #  print('X.shape =', X.shape)\n",
        "\n",
        "#    # Train HMM model for this iteration\n",
        "#    hmm_trainer = HMMTrainer()\n",
        "#    hmm_trainer.train(X)  # Train using the current MFCC features\n",
        "#    hmm_models.append((hmm_trainer, row['transcription']))\n",
        "#    hmm_trainer = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "YYhzPXAKSktn"
      },
      "outputs": [],
      "source": [
        "# test = ds.df.iloc[-1,:]\n",
        "# # Read the input file\n",
        "# audio, sampling_freq = librosa.load(test['path'])\n",
        "# # Extract MFCC features\n",
        "# mfcc_features = librosa.feature.mfcc(sr=sampling_freq, y=audio)\n",
        "# X = mfcc_features[:, :15]\n",
        "# y_word = test['transcription']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "haeYhQDoSKd8"
      },
      "outputs": [],
      "source": [
        "# scores = []\n",
        "# for hmm_model, _ in hmm_models:\n",
        "#     score = hmm_model.get_score(X)\n",
        "#     scores.append(score)\n",
        "\n",
        "# index = np.array(scores).argmax()\n",
        "# # Print the output\n",
        "# print(\"\\nTrue:\", y_word)\n",
        "# print(\"Predicted:\", hmm_models[index][1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchaudio ipywebrtc"
      ],
      "metadata": {
        "id": "JNLj_pPu_SFM",
        "outputId": "c62652de-23b8-416d-8219-d4abdb8a6f6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Collecting ipywebrtc\n",
            "  Downloading ipywebrtc-0.6.0-py2.py3-none-any.whl (260 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.7/260.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1->torchaudio)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1->torchaudio)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1->torchaudio)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1->torchaudio)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1->torchaudio)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1->torchaudio)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1->torchaudio)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1->torchaudio)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1->torchaudio)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1->torchaudio)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1->torchaudio)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchaudio) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchaudio)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->torchaudio) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->torchaudio) (1.3.0)\n",
            "Installing collected packages: ipywebrtc, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed ipywebrtc-0.6.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a static FFmpeg build and add it to PATH.\n",
        "exist = !which ffmpeg\n",
        "if not exist:\n",
        "  !curl https://johnvansickle.com/ffmpeg/releases/ffmpeg-release-amd64-static.tar.xz -o ffmpeg.tar.xz \\\n",
        "     && tar -xf ffmpeg.tar.xz && rm ffmpeg.tar.xz\n",
        "  ffmdir = !find . -iname ffmpeg-*-static\n",
        "  path = %env PATH\n",
        "  path = path + ':' + ffmdir[0]\n",
        "  %env PATH $path\n",
        "print('')\n",
        "!which ffmpeg\n",
        "print('Done!')"
      ],
      "metadata": {
        "id": "Eu4Hyy9_ApKs",
        "outputId": "fff3cbbe-f218-47a9-8d1b-bff017e4e629",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "/usr/bin/ffmpeg\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ipywebrtc import AudioRecorder, CameraStream\n",
        "import torchaudio\n",
        "from IPython.display import Audio\n",
        "\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "zpnBh8Mj_yJe"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "camera = CameraStream(constraints={'audio': True,'video':False})\n",
        "recorder = AudioRecorder(stream=camera)\n",
        "recorder"
      ],
      "metadata": {
        "id": "5ArqfZLk_0LD",
        "outputId": "4eec5232-df57-429b-8a3b-22d2bd8f5f6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107,
          "referenced_widgets": [
            "4074277a9c594fa083431be8bb1dd583",
            "9e722ee8394b4d7db77a9b5b330fbd61",
            "57c8bf77fe524449a4c8f2c1143f2b4b",
            "a30bca6c673a4dfaa49cd4e1a298ab31",
            "138412cd84184609a266a36fc3ea7dcf",
            "06fc803f1a4246e395521f6dc213a1ab"
          ]
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "AudioRecorder(audio=Audio(value=b'', format='webm'), stream=CameraStream(constraints={'audio': True, 'video': …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4074277a9c594fa083431be8bb1dd583"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write to recording.webm\n",
        "with open('recording.webm', 'wb') as f:\n",
        "    f.write(recorder.audio.value)\n",
        "\n",
        "# Translate recording.wemb to file.wav\n",
        "!ffmpeg -i recording.webm -ac 1 -f wav file.wav -y -hide_banner -loglevel panic\n",
        "\n",
        "# Extract features from input and predict\n",
        "input_audio, sr = librosa.load('file.wav')\n",
        "mfcc_features = librosa.feature.mfcc(sr=sr, y=input_audio)\n",
        "X = mfcc_features[:, :15]\n",
        "scores = []\n",
        "for hmm_model, label in hmm_models:\n",
        "  score = hmm_model.get_score(X)\n",
        "  scores.append(score)\n",
        "index = np.array(scores).argmax()\n",
        "print(\"Predicted:\", hmm_models[index][1])"
      ],
      "metadata": {
        "id": "GeKwvGZo_2EA",
        "outputId": "1708c8f3-2f41-48e1-8966-3b0a1581c493",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: peach\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4074277a9c594fa083431be8bb1dd583": {
          "model_module": "jupyter-webrtc",
          "model_name": "AudioRecorderModel",
          "model_module_version": "~0.6.0",
          "state": {
            "_data_src": "blob:https://0c7ghafktskt-496ff2e9c6d22116-0-colab.googleusercontent.com/122e7ee0-4143-478d-a204-e58b06a09a25",
            "_dom_classes": [],
            "_model_module": "jupyter-webrtc",
            "_model_module_version": "~0.6.0",
            "_model_name": "AudioRecorderModel",
            "_view_count": null,
            "_view_module": "jupyter-webrtc",
            "_view_module_version": "~0.6.0",
            "_view_name": "AudioRecorderView",
            "audio": "IPY_MODEL_9e722ee8394b4d7db77a9b5b330fbd61",
            "autosave": false,
            "codecs": "",
            "filename": "record",
            "format": "webm",
            "layout": "IPY_MODEL_57c8bf77fe524449a4c8f2c1143f2b4b",
            "recording": false,
            "stream": "IPY_MODEL_a30bca6c673a4dfaa49cd4e1a298ab31"
          }
        },
        "9e722ee8394b4d7db77a9b5b330fbd61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "AudioModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "AudioModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "AudioView",
            "autoplay": true,
            "controls": true,
            "format": "webm",
            "layout": "IPY_MODEL_138412cd84184609a266a36fc3ea7dcf",
            "loop": true
          }
        },
        "57c8bf77fe524449a4c8f2c1143f2b4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a30bca6c673a4dfaa49cd4e1a298ab31": {
          "model_module": "jupyter-webrtc",
          "model_name": "CameraStreamModel",
          "model_module_version": "~0.6.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "jupyter-webrtc",
            "_model_module_version": "~0.6.0",
            "_model_name": "CameraStreamModel",
            "_view_count": null,
            "_view_module": "jupyter-webrtc",
            "_view_module_version": "~0.6.0",
            "_view_name": "MediaStreamView",
            "constraints": {
              "audio": true,
              "video": false
            },
            "layout": "IPY_MODEL_06fc803f1a4246e395521f6dc213a1ab"
          }
        },
        "138412cd84184609a266a36fc3ea7dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06fc803f1a4246e395521f6dc213a1ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}