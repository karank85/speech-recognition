{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d5c9e18b28664db385ae4d1e8ee741c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6aee2c1be53f4a35ba0525fd5fb255f3",
              "IPY_MODEL_13000412a7ff470bb5b0c9b65e100c5b",
              "IPY_MODEL_f7b7bc1999414b8e9cb63df4d233ee55"
            ],
            "layout": "IPY_MODEL_5517228f1cbb443cb05901e9cb2bd13e"
          }
        },
        "6aee2c1be53f4a35ba0525fd5fb255f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9813d7eb5a094564bfaeb722c5c17dc5",
            "placeholder": "​",
            "style": "IPY_MODEL_94f0b9b00f74450c8aedc7d576a4ffd4",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "13000412a7ff470bb5b0c9b65e100c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bef4cdd8f9684266b763bab8a581cc70",
            "max": 60,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afdd0ab7d9d34b709eace4dea294fff9",
            "value": 60
          }
        },
        "f7b7bc1999414b8e9cb63df4d233ee55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4852456325b14cedab1ff2be5b166c83",
            "placeholder": "​",
            "style": "IPY_MODEL_747ee311e1f04c25b89a8cc2b0a56d51",
            "value": " 60/60 [00:08&lt;00:00, 10.57 examples/s]"
          }
        },
        "5517228f1cbb443cb05901e9cb2bd13e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9813d7eb5a094564bfaeb722c5c17dc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94f0b9b00f74450c8aedc7d576a4ffd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bef4cdd8f9684266b763bab8a581cc70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afdd0ab7d9d34b709eace4dea294fff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4852456325b14cedab1ff2be5b166c83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "747ee311e1f04c25b89a8cc2b0a56d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "048e829486194579b4b5bf1277e4f596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19111c0c7e794b39add91d61fa364e99",
              "IPY_MODEL_78c3a42bd68045bf831bbf58866e33ab",
              "IPY_MODEL_dbd8d539d8db4943a0da7e9d1324d747"
            ],
            "layout": "IPY_MODEL_2075fdaac8b24b01a5e2ce609cf9d550"
          }
        },
        "19111c0c7e794b39add91d61fa364e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75661b3591fa42e5b315bdd413f3c62f",
            "placeholder": "​",
            "style": "IPY_MODEL_8d41f19b2dc84377909bf8711dbb54b8",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "78c3a42bd68045bf831bbf58866e33ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e49b63a96dcb41f6b0ca630c3d73798a",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_affa791a66984c5b8b6f70c24fba7883",
            "value": 16
          }
        },
        "dbd8d539d8db4943a0da7e9d1324d747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff0e34b21f6544159bafe2ea3b71c325",
            "placeholder": "​",
            "style": "IPY_MODEL_6c0486b321d7456ca7424c3eeca367b8",
            "value": " 16/16 [00:05&lt;00:00,  6.74 examples/s]"
          }
        },
        "2075fdaac8b24b01a5e2ce609cf9d550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75661b3591fa42e5b315bdd413f3c62f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d41f19b2dc84377909bf8711dbb54b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e49b63a96dcb41f6b0ca630c3d73798a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "affa791a66984c5b8b6f70c24fba7883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff0e34b21f6544159bafe2ea3b71c325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c0486b321d7456ca7424c3eeca367b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karank85/speech-recognition/blob/main/Project2_DL_Speech_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QZycw3QagLpa",
        "outputId": "3627a834-d52c-4cff-c78e-2300f24aead3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.39.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.6.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from numpy import ndarray\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, List, Optional, Union\n",
        "\n",
        "import librosa\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import librosa.display\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch import nn\n",
        "\n",
        "import glob\n",
        "\n",
        "!pip install transformers datasets evaluate jiwer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "librosa.__version__"
      ],
      "metadata": {
        "id": "3w9t1VF0gRQq",
        "outputId": "fa9ae905-39c8-4202-db95-9d39157dbebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.10.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device-agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "F_jS9kfO3wpo",
        "outputId": "c91769f3-4b46-4d20-f7db-96b372d7f6f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hsP0jZs-gTMe",
        "outputId": "f35bbfab-74dd-4949-e3b0-deff7566924e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assumptions:\n",
        "# - The transcription file is located in the same directory as the audio files.\n",
        "class AudioDataset:\n",
        "  \"\"\"\n",
        "  Class for loading and storing audio data.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self.df = pd.DataFrame(columns=['id', 'path', 'transcription'])\n",
        "\n",
        "  def load_transcriptions(self, directory_path: str) -> bool:\n",
        "    \"\"\"\n",
        "    Load all transcriptions from a given directory, including subdirectories.\n",
        "    Returns False if no transcription files were found, or if any failed to load.\n",
        "    \"\"\"\n",
        "    transcriptions_path = glob.glob(\n",
        "        f\"{directory_path}/**/*.trans.txt\",\n",
        "        recursive=True\n",
        "    )\n",
        "\n",
        "    if len(transcriptions_path) == 0:\n",
        "      return False\n",
        "\n",
        "    for path in transcriptions_path:\n",
        "      if not self.load_transcription_file(path):\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "  def load_transcription_file(self, file_path: str) -> bool:\n",
        "    \"\"\"\n",
        "    Parse transcription file and records the audio ID - subtitle mapping.\n",
        "    Returns False if the file could not be read.\n",
        "    \"\"\"\n",
        "    with open(file_path, \"r\") as file:\n",
        "      file_directory = os.path.dirname(file_path)\n",
        "\n",
        "      lines = file.read().split(\"\\n\")\n",
        "      for line in lines:\n",
        "        if len(line.strip()) == 0:\n",
        "          continue\n",
        "        splitter = line.split(\" \")\n",
        "        file_name = splitter[0]\n",
        "        file_content = ' '.join(splitter[1:])\n",
        "        self.df.loc[len(self.df)] = {\n",
        "            'id':file_name,\n",
        "            'transcription':file_content,\n",
        "            'path': f'{file_directory}/{file_name}.flac'\n",
        "        }\n",
        "      return True\n",
        "    return False\n",
        "\n",
        "  def keys(self):\n",
        "    return iter(self.df['id'])\n",
        "\n",
        "  def get(self, id: int):\n",
        "    \"\"\"\n",
        "    Retrieve a dataframe row from ID.\n",
        "    \"\"\"\n",
        "    return self.df.loc[self.df['id'] == id]"
      ],
      "metadata": {
        "id": "rQKj6v9RgdKa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = AudioDataset()"
      ],
      "metadata": {
        "id": "uFti1k8ighEU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.load_transcriptions(\"/content/drive/MyDrive/\")"
      ],
      "metadata": {
        "id": "FC6BlmBgghWT",
        "outputId": "36d0572e-7c5c-4f8e-c23f-8ae18b465b80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_list = []\n",
        "sampling_freq_list = []\n",
        "\n",
        "for index, row in ds.df.iterrows():\n",
        "  audio, sampling_freq = librosa.load(row['path'], sr=16_000)\n",
        "\n",
        "  audio_list.append(audio)\n",
        "  sampling_freq_list.append(sampling_freq)\n",
        "\n",
        "ds.df['audio'] = audio_list\n",
        "ds.df['sampling_freq'] = sampling_freq_list"
      ],
      "metadata": {
        "id": "CUB0YyBgyQzm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, Features, Array3D, Value\n",
        "\n",
        "custom_dataset = Dataset.from_pandas(ds.df)\n",
        "custom_dataset"
      ],
      "metadata": {
        "id": "-X_R8KuSoIA0",
        "outputId": "e6641302-cd14-41d7-ee06-28bb2ef61913",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'path', 'transcription', 'audio', 'sampling_freq', '__index_level_0__'],\n",
              "    num_rows: 76\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_dataset = custom_dataset.remove_columns(['path', 'id', '__index_level_0__'])\n",
        "# transcription: str, audio: list[int], sampling_freq: int\n",
        "custom_dataset"
      ],
      "metadata": {
        "id": "-t7Nuh2x0tvV",
        "outputId": "ed480b5e-4fef-4115-ad45-2bd257477b16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['transcription', 'audio', 'sampling_freq'],\n",
              "    num_rows: 76\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_dataset = custom_dataset.train_test_split(test_size=0.2)\n",
        "custom_dataset"
      ],
      "metadata": {
        "id": "Y1OXGX_9THIO",
        "outputId": "dfbf2a64-f201-46df-d21a-c6ad0a21cb71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['transcription', 'audio', 'sampling_freq'],\n",
              "        num_rows: 60\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['transcription', 'audio', 'sampling_freq'],\n",
              "        num_rows: 16\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Making sure it's all uppercase characters as Wav2Vec Tokenizer is only trained\n",
        "# on uppercase characters and we need to match the tokenizer's vocabulary.\n",
        "for item in custom_dataset[\"train\"]:\n",
        "  print(item[\"transcription\"])"
      ],
      "metadata": {
        "id": "qZcS35Sy-8RH",
        "outputId": "b8e39793-9565-4e11-df14-fe46d6166ff2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THERE SHE FELL MISERABLY SHORT OF THE TRUE HEROIC HEIGHT AT PRESENT SHE DID NOT KNOW HER OWN POVERTY FOR SHE HAD NO LOVER TO PORTRAY SHE HAD REACHED THE AGE OF SEVENTEEN\n",
            "FRENCH BY HER MOTHER HER PROFICIENCY IN EITHER WAS NOT REMARKABLE AND SHE SHIRKED HER LESSONS IN BOTH WHENEVER SHE COULD WHAT A STRANGE UNACCOUNTABLE CHARACTER FOR WITH ALL THESE SYMPTOMS OF PROFLIGACY AT TEN YEARS OLD\n",
            "DARK LANK HAIR AND STRONG FEATURES SO MUCH FOR HER PERSON AND NOT LESS UNPROPITIOUS FOR HEROISM SEEMED HER MIND SHE WAS FOND OF ALL BOY'S PLAYS AND GREATLY PREFERRED CRICKET\n",
            "THERE WAS NOT ONE FAMILY AMONG THEIR ACQUAINTANCE WHO HAD REARED AND SUPPORTED A BOY ACCIDENTALLY FOUND AT THEIR DOOR NOT ONE YOUNG MAN WHOSE ORIGIN WAS UNKNOWN HER FATHER HAD NO WARD AND THE SQUIRE OF THE PARISH NO CHILDREN\n",
            "WHO OWNED THE CHIEF OF THE PROPERTY ABOUT FULLERTON THE VILLAGE IN WILTSHIRE WHERE THE MORLANDS LIVED WAS ORDERED TO BATH FOR THE BENEFIT OF A GOUTY CONSTITUTION AND HIS LADY A GOOD HUMOURED WOMAN FOND OF MISS MORLAND AND PROBABLY AWARE THAT IF\n",
            "HER MOTHER WAS A WOMAN OF USEFUL PLAIN SENSE WITH A GOOD TEMPER AND WHAT IS MORE REMARKABLE WITH A GOOD CONSTITUTION SHE HAD THREE SONS BEFORE CATHERINE WAS BORN\n",
            "THE PUBLIC ARE ENTREATED TO BEAR IN MIND THAT THIRTEEN YEARS HAVE PASSED SINCE IT WAS FINISHED MANY MORE SINCE IT WAS BEGUN AND THAT DURING THAT PERIOD PLACES MANNERS BOOKS AND OPINIONS HAVE UNDERGONE CONSIDERABLE CHANGES\n",
            "CHAPTER ONE NO ONE WHO HAD EVER SEEN CATHERINE MORLAND IN HER INFANCY WOULD HAVE SUPPOSED HER BORN TO BE AN HEROINE HER SITUATION IN LIFE\n",
            "SHE HAD NEVER ANY OBJECTION TO BOOKS AT ALL BUT FROM FIFTEEN TO SEVENTEEN SHE WAS IN TRAINING FOR A HEROINE SHE READ ALL SUCH WORKS AS HEROINES MUST READ TO SUPPLY THEIR MEMORIES WITH THOSE QUOTATIONS WHICH ARE SO SERVICEABLE\n",
            "HER GREATEST DEFICIENCY WAS IN THE PENCIL SHE HAD NO NOTION OF DRAWING NOT ENOUGH EVEN TO ATTEMPT A SKETCH OF HER LOVER'S PROFILE THAT SHE MIGHT BE DETECTED IN THE DESIGN\n",
            "SHE BEGAN TO CURL HER HAIR AND LONG FOR BALLS HER COMPLEXION IMPROVED HER FEATURES WERE SOFTENED BY PLUMPNESS AND COLOUR HER EYES GAINED MORE ANIMATION AND HER FIGURE MORE CONSEQUENCE\n",
            "THAT THE POOR BEETLE WHICH WE TREAD UPON IN CORPORAL SUFFERANCE FEELS A PANG AS GREAT AS WHEN A GIANT DIES AND THAT A YOUNG WOMAN IN LOVE ALWAYS LOOKS\n",
            "HER ABILITIES WERE QUITE AS EXTRAORDINARY SHE NEVER COULD LEARN OR UNDERSTAND ANYTHING BEFORE SHE WAS TAUGHT AND SOMETIMES NOT EVEN THEN FOR SHE WAS OFTEN INATTENTIVE AND OCCASIONALLY STUPID\n",
            "SHE LEARNT THE FABLE OF THE HARE AND MANY FRIENDS AS QUICKLY AS ANY GIRL IN ENGLAND HER MOTHER WISHED HER TO LEARN MUSIC AND CATHERINE WAS SURE SHE SHOULD LIKE IT FOR SHE WAS VERY FOND OF TINKLING THE KEYS OF THE OLD FORLORN SPINNET\n",
            "SHE BROUGHT HERSELF TO READ THEM AND THOUGH THERE SEEMED NO CHANCE OF HER THROWING A WHOLE PARTY INTO RAPTURES BY A PRELUDE ON THE PIANOFORTE OF HER OWN COMPOSITION SHE COULD LISTEN TO OTHER PEOPLE'S PERFORMANCE WITH VERY LITTLE FATIGUE\n",
            "SHE HAD A THIN AWKWARD FIGURE\n",
            "HER LOVE OF DIRT GAVE WAY TO AN INCLINATION FOR FINERY AND SHE GREW CLEAN AS SHE GREW SMART SHE HAD NOW THE PLEASURE OF SOMETIMES HEARING HER FATHER AND MOTHER REMARK ON HER PERSONAL IMPROVEMENT\n",
            "SHE BROUGHT HERSELF TO READ THEM AND THOUGH THERE SEEMED NO CHANCE OF HER THROWING A WHOLE PARTY INTO RAPTURES BY A PRELUDE ON THE PIANOFORTE OF HER OWN COMPOSITION SHE COULD LISTEN TO OTHER PEOPLE'S PERFORMANCE WITH VERY LITTLE FATIGUE\n",
            "HER MOTHER WAS THREE MONTHS IN TEACHING HER ONLY TO REPEAT THE BEGGAR'S PETITION AND AFTER ALL HER NEXT SISTER SALLY COULD SAY IT BETTER THAN SHE DID NOT THAT CATHERINE WAS ALWAYS STUPID BY NO MEANS\n",
            "LIKE PATIENCE ON A MONUMENT SMILING AT GRIEF SO FAR HER IMPROVEMENT WAS SUFFICIENT AND IN MANY OTHER POINTS SHE CAME ON EXCEEDINGLY WELL FOR THOUGH SHE COULD NOT WRITE SONNETS\n",
            "AND IF SHE GATHERED FLOWERS AT ALL IT WAS CHIEFLY FOR THE PLEASURE OF MISCHIEF AT LEAST SO IT WAS CONJECTURED FROM HER ALWAYS PREFERRING THOSE WHICH SHE WAS FORBIDDEN TO TAKE SUCH WERE HER PROPENSITIES\n",
            "NORTHANGER ABBEY\n",
            "BUT WHEN A YOUNG LADY IS TO BE A HEROINE THE PERVERSENESS OF FORTY SURROUNDING FAMILIES CANNOT PREVENT HER SOMETHING MUST AND WILL HAPPEN TO THROW A HERO IN HER WAY MISTER ALLEN\n",
            "THAT THE POOR BEETLE WHICH WE TREAD UPON IN CORPORAL SUFFERANCE FEELS A PANG AS GREAT AS WHEN A GIANT DIES AND THAT A YOUNG WOMAN IN LOVE ALWAYS LOOKS\n",
            "HATED CONFINEMENT AND CLEANLINESS AND LOVED NOTHING SO WELL IN THE WORLD AS ROLLING DOWN THE GREEN SLOPE AT THE BACK OF THE HOUSE SUCH WAS CATHERINE MORLAND AT TEN AT FIFTEEN APPEARANCES WERE MENDING\n",
            "BUT WHEN A YOUNG LADY IS TO BE A HEROINE THE PERVERSENESS OF FORTY SURROUNDING FAMILIES CANNOT PREVENT HER SOMETHING MUST AND WILL HAPPEN TO THROW A HERO IN HER WAY MISTER ALLEN\n",
            "SHE BEGAN TO CURL HER HAIR AND LONG FOR BALLS HER COMPLEXION IMPROVED HER FEATURES WERE SOFTENED BY PLUMPNESS AND COLOUR HER EYES GAINED MORE ANIMATION AND HER FIGURE MORE CONSEQUENCE\n",
            "LIKE PATIENCE ON A MONUMENT SMILING AT GRIEF SO FAR HER IMPROVEMENT WAS SUFFICIENT AND IN MANY OTHER POINTS SHE CAME ON EXCEEDINGLY WELL FOR THOUGH SHE COULD NOT WRITE SONNETS\n",
            "MANY A FLOWER IS BORN TO BLUSH UNSEEN AND WASTE ITS FRAGRANCE ON THE DESERT AIR FROM THOMPSON THAT IT IS A DELIGHTFUL TASK TO TEACH THE YOUNG IDEA HOW TO SHOOT\n",
            "SHE HAD NEVER ANY OBJECTION TO BOOKS AT ALL BUT FROM FIFTEEN TO SEVENTEEN SHE WAS IN TRAINING FOR A HEROINE SHE READ ALL SUCH WORKS AS HEROINES MUST READ TO SUPPLY THEIR MEMORIES WITH THOSE QUOTATIONS WHICH ARE SO SERVICEABLE\n",
            "THE CHARACTER OF HER FATHER AND MOTHER HER OWN PERSON AND DISPOSITION WERE ALL EQUALLY AGAINST HER HER FATHER WAS A CLERGYMAN WITHOUT BEING NEGLECTED OR POOR AND A VERY RESPECTABLE MAN\n",
            "THAN A BEAUTY FROM HER CRADLE CAN EVER RECEIVE MISSUS MORLAND WAS A VERY GOOD WOMAN AND WISHED TO SEE HER CHILDREN EVERYTHING THEY OUGHT TO BE BUT HER TIME WAS SO MUCH OCCUPIED IN LYING IN AND TEACHING THE LITTLE ONES\n",
            "THE PUBLIC ARE ENTREATED TO BEAR IN MIND THAT THIRTEEN YEARS HAVE PASSED SINCE IT WAS FINISHED MANY MORE SINCE IT WAS BEGUN AND THAT DURING THAT PERIOD PLACES MANNERS BOOKS AND OPINIONS HAVE UNDERGONE CONSIDERABLE CHANGES\n",
            "MANY A FLOWER IS BORN TO BLUSH UNSEEN AND WASTE ITS FRAGRANCE ON THE DESERT AIR FROM THOMPSON THAT IT IS A DELIGHTFUL TASK TO TEACH THE YOUNG IDEA HOW TO SHOOT\n",
            "CATHERINE GROWS QUITE A GOOD LOOKING GIRL SHE IS ALMOST PRETTY TODAY WERE WORDS WHICH CAUGHT HER EARS NOW AND THEN AND HOW WELCOME WERE THE SOUNDS TO LOOK ALMOST PRETTY\n",
            "NOT MERELY TO DOLLS BUT TO THE MORE HEROIC ENJOYMENTS OF INFANCY NURSING A DORMOUSE FEEDING A CANARY BIRD OR WATERING A ROSE BUSH INDEED SHE HAD NO TASTE FOR A GARDEN\n",
            "NEITHER THE AUTHOR NOR THE PUBLIC HAVE ANY OTHER CONCERN THAN AS SOME OBSERVATION IS NECESSARY UPON THOSE PARTS OF THE WORK WHICH THIRTEEN YEARS HAVE MADE COMPARATIVELY OBSOLETE\n",
            "THERE SHE FELL MISERABLY SHORT OF THE TRUE HEROIC HEIGHT AT PRESENT SHE DID NOT KNOW HER OWN POVERTY FOR SHE HAD NO LOVER TO PORTRAY SHE HAD REACHED THE AGE OF SEVENTEEN\n",
            "THIS WAS STRANGE INDEED BUT STRANGE THINGS MAY BE GENERALLY ACCOUNTED FOR IF THEIR CAUSE BE FAIRLY SEARCHED OUT THERE WAS NOT ONE LORD IN THE NEIGHBOURHOOD NO NOT EVEN A BARONET\n",
            "SHE MUST SEEK THEM ABROAD INVITED HER TO GO WITH THEM\n",
            "SO AT EIGHT YEARS OLD SHE BEGAN SHE LEARNT A YEAR AND COULD NOT BEAR IT AND MISSUS MORLAND WHO DID NOT INSIST ON HER DAUGHTERS BEING ACCOMPLISHED IN SPITE OF INCAPACITY OR DISTASTE ALLOWED HER TO LEAVE OFF\n",
            "THE CHARACTER OF HER FATHER AND MOTHER HER OWN PERSON AND DISPOSITION WERE ALL EQUALLY AGAINST HER HER FATHER WAS A CLERGYMAN WITHOUT BEING NEGLECTED OR POOR AND A VERY RESPECTABLE MAN\n",
            "HER ABILITIES WERE QUITE AS EXTRAORDINARY SHE NEVER COULD LEARN OR UNDERSTAND ANYTHING BEFORE SHE WAS TAUGHT AND SOMETIMES NOT EVEN THEN FOR SHE WAS OFTEN INATTENTIVE AND OCCASIONALLY STUPID\n",
            "AND RUNNING ABOUT THE COUNTRY AT THE AGE OF FOURTEEN TO BOOKS OR AT LEAST BOOKS OF INFORMATION FOR PROVIDED THAT NOTHING LIKE USEFUL KNOWLEDGE COULD BE GAINED FROM THEM PROVIDED THEY WERE ALL STORY AND NO REFLECTION\n",
            "NORTHANGER ABBEY\n",
            "THAT HER ELDER DAUGHTERS WERE INEVITABLY LEFT TO SHIFT FOR THEMSELVES AND IT WAS NOT VERY WONDERFUL THAT CATHERINE WHO HAD BY NATURE NOTHING HEROIC ABOUT HER SHOULD PREFER CRICKET BASEBALL RIDING ON HORSEBACK\n",
            "THAT HER ELDER DAUGHTERS WERE INEVITABLY LEFT TO SHIFT FOR THEMSELVES AND IT WAS NOT VERY WONDERFUL THAT CATHERINE WHO HAD BY NATURE NOTHING HEROIC ABOUT HER SHOULD PREFER CRICKET BASEBALL RIDING ON HORSEBACK\n",
            "THIS LITTLE WORK WAS FINISHED IN THE YEAR EIGHTEEN O THREE AND INTENDED FOR IMMEDIATE PUBLICATION IT WAS DISPOSED OF TO A BOOKSELLER IT WAS EVEN ADVERTISED\n",
            "SHE LEARNT THE FABLE OF THE HARE AND MANY FRIENDS AS QUICKLY AS ANY GIRL IN ENGLAND HER MOTHER WISHED HER TO LEARN MUSIC AND CATHERINE WAS SURE SHE SHOULD LIKE IT FOR SHE WAS VERY FOND OF TINKLING THE KEYS OF THE OLD FORLORN SPINNET\n",
            "NEITHER THE AUTHOR NOR THE PUBLIC HAVE ANY OTHER CONCERN THAN AS SOME OBSERVATION IS NECESSARY UPON THOSE PARTS OF THE WORK WHICH THIRTEEN YEARS HAVE MADE COMPARATIVELY OBSOLETE\n",
            "WITHOUT HAVING SEEN ONE AMIABLE YOUTH WHO COULD CALL FORTH HER SENSIBILITY WITHOUT HAVING INSPIRED ONE REAL PASSION AND WITHOUT HAVING EXCITED EVEN ANY ADMIRATION BUT WHAT WAS VERY MODERATE AND VERY TRANSIENT\n",
            "SHE MUST SEEK THEM ABROAD INVITED HER TO GO WITH THEM\n",
            "WHERE THERE ARE HEADS AND ARMS AND LEGS ENOUGH FOR THE NUMBER BUT THE MORLANDS HAD LITTLE OTHER RIGHT TO THE WORD FOR THEY WERE IN GENERAL VERY PLAIN AND CATHERINE FOR MANY YEARS OF HER LIFE AS PLAIN AS ANY\n",
            "AND IF SHE GATHERED FLOWERS AT ALL IT WAS CHIEFLY FOR THE PLEASURE OF MISCHIEF AT LEAST SO IT WAS CONJECTURED FROM HER ALWAYS PREFERRING THOSE WHICH SHE WAS FORBIDDEN TO TAKE SUCH WERE HER PROPENSITIES\n",
            "SHE HAD A THIN AWKWARD FIGURE\n",
            "DARK LANK HAIR AND STRONG FEATURES SO MUCH FOR HER PERSON AND NOT LESS UNPROPITIOUS FOR HEROISM SEEMED HER MIND SHE WAS FOND OF ALL BOY'S PLAYS AND GREATLY PREFERRED CRICKET\n",
            "AND FROM SHAKESPEARE SHE GAINED A GREAT STORE OF INFORMATION AMONGST THE REST THAT TRIFLES LIGHT AS AIR ARE TO THE JEALOUS CONFIRMATION STRONG AS PROOFS OF HOLY WRIT\n",
            "THERE WAS NOT ONE FAMILY AMONG THEIR ACQUAINTANCE WHO HAD REARED AND SUPPORTED A BOY ACCIDENTALLY FOUND AT THEIR DOOR NOT ONE YOUNG MAN WHOSE ORIGIN WAS UNKNOWN HER FATHER HAD NO WARD AND THE SQUIRE OF THE PARISH NO CHILDREN\n",
            "NOT MERELY TO DOLLS BUT TO THE MORE HEROIC ENJOYMENTS OF INFANCY NURSING A DORMOUSE FEEDING A CANARY BIRD OR WATERING A ROSE BUSH INDEED SHE HAD NO TASTE FOR A GARDEN\n",
            "HER MOTHER WAS THREE MONTHS IN TEACHING HER ONLY TO REPEAT THE BEGGAR'S PETITION AND AFTER ALL HER NEXT SISTER SALLY COULD SAY IT BETTER THAN SHE DID NOT THAT CATHERINE WAS ALWAYS STUPID BY NO MEANS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base\")"
      ],
      "metadata": {
        "id": "0u7TJisQoczk",
        "outputId": "8e56ec2a-a421-4fc3-f9a5-f4b4bb1bfe45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Z0a-oeX7BRT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_processor(batch):\n",
        "  batch = processor(batch[\"audio\"], sampling_rate=batch[\"sampling_freq\"], text=batch[\"transcription\"])\n",
        "  batch[\"input_length\"] = len(batch[\"input_values\"][0])\n",
        "  return batch\n",
        "\n",
        "encoded_datasets = custom_dataset.map(apply_processor, remove_columns=custom_dataset.column_names[\"train\"], num_proc=4)"
      ],
      "metadata": {
        "id": "CB97Kll01geD",
        "outputId": "94049f2c-e675-473a-eb38-c3c958566929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "d5c9e18b28664db385ae4d1e8ee741c2",
            "6aee2c1be53f4a35ba0525fd5fb255f3",
            "13000412a7ff470bb5b0c9b65e100c5b",
            "f7b7bc1999414b8e9cb63df4d233ee55",
            "5517228f1cbb443cb05901e9cb2bd13e",
            "9813d7eb5a094564bfaeb722c5c17dc5",
            "94f0b9b00f74450c8aedc7d576a4ffd4",
            "bef4cdd8f9684266b763bab8a581cc70",
            "afdd0ab7d9d34b709eace4dea294fff9",
            "4852456325b14cedab1ff2be5b166c83",
            "747ee311e1f04c25b89a8cc2b0a56d51",
            "048e829486194579b4b5bf1277e4f596",
            "19111c0c7e794b39add91d61fa364e99",
            "78c3a42bd68045bf831bbf58866e33ab",
            "dbd8d539d8db4943a0da7e9d1324d747",
            "2075fdaac8b24b01a5e2ce609cf9d550",
            "75661b3591fa42e5b315bdd413f3c62f",
            "8d41f19b2dc84377909bf8711dbb54b8",
            "e49b63a96dcb41f6b0ca630c3d73798a",
            "affa791a66984c5b8b6f70c24fba7883",
            "ff0e34b21f6544159bafe2ea3b71c325",
            "6c0486b321d7456ca7424c3eeca367b8"
          ]
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/60 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5c9e18b28664db385ae4d1e8ee741c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/16 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "048e829486194579b4b5bf1277e4f596"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to create a data collator to prepare batches of data suitable for training CTC loss-based models\n",
        "# Pad text and labels to length of the longest element in its batch to make it uniform length\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorCTCLossWithPadding:\n",
        "  processor: AutoProcessor\n",
        "  padding: Union[bool, str] = \"longest\" # pad to the longest sequence\n",
        "\n",
        "  def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "\n",
        "    #audio features\n",
        "    input_features = [{\"input_values\": feature[\"input_values\"][0]} for feature in features]\n",
        "    # tokenized labels\n",
        "    label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "\n",
        "    batch = self.processor.pad(input_features, padding=self.padding, return_tensors=\"pt\")\n",
        "\n",
        "    labels_batch = self.processor.pad(labels=label_features, padding=self.padding, return_tensors=\"pt\")\n",
        "\n",
        "    # replace padding with -100 to ignore loss correctly\n",
        "    labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attentions_mask.ne(1), -100)\n",
        "\n",
        "    batch[\"labels\"] = labels\n",
        "\n",
        "    return batch"
      ],
      "metadata": {
        "id": "n7fMhqGrAX-r"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorCTCLossWithPadding(processor=processor, padding=\"longest\")"
      ],
      "metadata": {
        "id": "IWgnruMcIqms"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wave2Vec2.0"
      ],
      "metadata": {
        "id": "TMiiBtWW4tii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "\n",
        "tokenizer = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base\")"
      ],
      "metadata": {
        "id": "rx6yOxj4lMre",
        "outputId": "dc9ba6bf-0d2b-472d-d2f7-e42dd24dea64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py:363: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['lm_head.bias', 'lm_head.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "wer = evaluate.load(\"wer\")"
      ],
      "metadata": {
        "id": "Qra36dYO1_Kg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    # Compute predicted labels\n",
        "    pred_logits = pred.predictions\n",
        "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
        "    pred_str = processor.batch_decode(pred_ids)\n",
        "\n",
        "    # Replace -100 with pad token ID in true labels\n",
        "    true_labels = np.where(pred.label_ids == -100, processor.tokenizer.pad_token_id, pred.label_ids)\n",
        "    true_str = processor.batch_decode(true_labels, group_tokens=False)\n",
        "\n",
        "    # Compute Word Error Rate (WER)\n",
        "    wer_score = wer.compute(predictions=pred_str, references=true_str)\n",
        "\n",
        "    return {\"wer\": wer_score}\n"
      ],
      "metadata": {
        "id": "6o9k0lfV3yMU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCTC\n",
        "\n",
        "model = AutoModelForCTC.from_pretrained(\n",
        "    \"facebook/wav2vec2-base\",\n",
        "    ctc_loss_reduction=\"mean\",\n",
        "    pad_token_id=processor.tokenizer.pad_token_id,\n",
        ")"
      ],
      "metadata": {
        "id": "qzBrYrqAC6IH",
        "outputId": "caed91b8-79e3-45ad-a5fb-d492757ab5d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['lm_head.bias', 'lm_head.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U accelerate\n",
        "!pip install -U transformers\n",
        "\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"wav2vec_model_v1\",\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=1e-5,\n",
        "    warmup_steps=500,\n",
        "    max_steps=2000,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    group_by_length=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_eval_batch_size=8,\n",
        "    save_steps=1000,\n",
        "    eval_steps=1000,\n",
        "    logging_steps=25,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"wer\",\n",
        "    greater_is_better=False,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_datasets[\"train\"],\n",
        "    eval_dataset=encoded_datasets[\"test\"],\n",
        "    tokenizer=processor,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "omPJvI78DFEN",
        "outputId": "b5d705f1-f552-4916-9fef-bb382be1d530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/290.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m245.8/290.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.28.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.39.1-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "Successfully installed transformers-4.39.1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "FP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation (`--fp16_full_eval`) can only be used on CUDA or NPU devices or certain XPU devices (with IPEX).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d365b7bf1fcc>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"wav2vec_model_v1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mper_device_train_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp...\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1555\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16_full_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m         ):\n\u001b[0;32m-> 1557\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1558\u001b[0m                 \u001b[0;34m\"FP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m                 \u001b[0;34m\" (`--fp16_full_eval`) can only be used on CUDA or NPU devices or certain XPU devices (with IPEX).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: FP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation (`--fp16_full_eval`) can only be used on CUDA or NPU devices or certain XPU devices (with IPEX)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M3gsgUzcDGj0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}