{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiTpDFwAX+z0/ABOPgV9nN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karank85/speech-recognition/blob/main/Project2_DL_Speech_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZycw3QagLpa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from numpy import ndarray\n",
        "import pandas as pd\n",
        "\n",
        "import librosa\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import librosa.display\n",
        "from tqdm import tqdm\n",
        "\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "librosa.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3w9t1VF0gRQq",
        "outputId": "925906af-0a58-411c-fe65-5472a3d5b82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.10.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hsP0jZs-gTMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assumptions:\n",
        "# - The transcription file is located in the same directory as the audio files.\n",
        "class AudioDataset:\n",
        "  \"\"\"\n",
        "  Class for loading and storing audio data.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self.df = pd.DataFrame(columns=['id', 'path', 'transcription'])\n",
        "\n",
        "  def load_transcriptions(self, directory_path: str) -> bool:\n",
        "    \"\"\"\n",
        "    Load all transcriptions from a given directory, including subdirectories.\n",
        "    Returns False if no transcription files were found, or if any failed to load.\n",
        "    \"\"\"\n",
        "    transcriptions_path = glob.glob(\n",
        "        f\"{directory_path}/**/*.trans.txt\",\n",
        "        recursive=True\n",
        "    )\n",
        "\n",
        "    if len(transcriptions_path) == 0:\n",
        "      return False\n",
        "\n",
        "    for path in transcriptions_path:\n",
        "      if not self.load_transcription_file(path):\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "  def load_transcription_file(self, file_path: str) -> bool:\n",
        "    \"\"\"\n",
        "    Parse transcription file and records the audio ID - subtitle mapping.\n",
        "    Returns False if the file could not be read.\n",
        "    \"\"\"\n",
        "    with open(file_path, \"r\") as file:\n",
        "      file_directory = os.path.dirname(file_path)\n",
        "\n",
        "      lines = file.read().split(\"\\n\")\n",
        "      for line in lines:\n",
        "        if len(line.strip()) == 0:\n",
        "          continue\n",
        "        splitter = line.split(\" \")\n",
        "        file_name = splitter[0]\n",
        "        file_content = ' '.join(splitter[1:])\n",
        "        self.df.loc[len(self.df)] = {\n",
        "            'id':file_name,\n",
        "            'transcription':file_content,\n",
        "            'path': f'{file_directory}/{file_name}.flac'\n",
        "        }\n",
        "      return True\n",
        "    return False\n",
        "\n",
        "  def keys(self):\n",
        "    return iter(self.df['id'])\n",
        "\n",
        "  def get(self, id: int):\n",
        "    \"\"\"\n",
        "    Retrieve a dataframe row from ID.\n",
        "    \"\"\"\n",
        "    return self.df.loc[self.df['id'] == id]"
      ],
      "metadata": {
        "id": "rQKj6v9RgdKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = AudioDataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "uFti1k8ighEU",
        "outputId": "e64d69b5-ff3d-4018-d1f1-3db056d498a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'AudioDataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d061b6492d00>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'AudioDataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds.load_transcriptions(\"/content/drive/MyDrive/datasets\")\n"
      ],
      "metadata": {
        "id": "FC6BlmBgghWT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}