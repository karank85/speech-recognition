{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzVorJ9mJvonzRAqLf5+WG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karank85/speech-recognition/blob/main/Project2_DL_Speech_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZycw3QagLpa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from numpy import ndarray\n",
        "import pandas as pd\n",
        "\n",
        "import librosa\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import librosa.display\n",
        "from tqdm import tqdm\n",
        "\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "librosa.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3w9t1VF0gRQq",
        "outputId": "7f9d5e24-e427-4710-e1e9-33e49c092a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.10.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "hsP0jZs-gTMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ef5e990-2226-48db-96af-c1c849e13b1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assumptions:\n",
        "# - The transcription file is located in the same directory as the audio files.\n",
        "class AudioDataset:\n",
        "  \"\"\"\n",
        "  Class for loading and storing audio data.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self.df = pd.DataFrame(columns=['id', 'path', 'transcription'])\n",
        "\n",
        "  def load_transcriptions(self, directory_path: str) -> bool:\n",
        "    \"\"\"\n",
        "    Load all transcriptions from a given directory, including subdirectories.\n",
        "    Returns False if no transcription files were found, or if any failed to load.\n",
        "    \"\"\"\n",
        "    transcriptions_path = glob.glob(\n",
        "        f\"{directory_path}/**/*.trans.txt\",\n",
        "        recursive=True\n",
        "    )\n",
        "\n",
        "    if len(transcriptions_path) == 0:\n",
        "      return False\n",
        "\n",
        "    for path in transcriptions_path:\n",
        "      if not self.load_transcription_file(path):\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "\n",
        "  def load_transcription_file(self, file_path: str) -> bool:\n",
        "    \"\"\"\n",
        "    Parse transcription file and records the audio ID - subtitle mapping.\n",
        "    Returns False if the file could not be read.\n",
        "    \"\"\"\n",
        "    with open(file_path, \"r\") as file:\n",
        "      file_directory = os.path.dirname(file_path)\n",
        "\n",
        "      lines = file.read().split(\"\\n\")\n",
        "      for line in lines:\n",
        "        if len(line.strip()) == 0:\n",
        "          continue\n",
        "        splitter = line.split(\" \")\n",
        "        file_name = splitter[0]\n",
        "        file_content = ' '.join(splitter[1:])\n",
        "        self.df.loc[len(self.df)] = {\n",
        "            'id':file_name,\n",
        "            'transcription':file_content,\n",
        "            'path': f'{file_directory}/{file_name}.flac'\n",
        "        }\n",
        "      return True\n",
        "    return False\n",
        "\n",
        "  def keys(self):\n",
        "    return iter(self.df['id'])\n",
        "\n",
        "  def get(self, id: int):\n",
        "    \"\"\"\n",
        "    Retrieve a dataframe row from ID.\n",
        "    \"\"\"\n",
        "    return self.df.loc[self.df['id'] == id]"
      ],
      "metadata": {
        "id": "rQKj6v9RgdKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = AudioDataset()"
      ],
      "metadata": {
        "id": "uFti1k8ighEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.load_transcriptions(\"/content/drive/MyDrive/\")\n"
      ],
      "metadata": {
        "id": "FC6BlmBgghWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d4767b1-90ba-45de-9e67-5d512c4118ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wave2Vec2.0 Model Framework"
      ],
      "metadata": {
        "id": "TMiiBtWW4tii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameters"
      ],
      "metadata": {
        "id": "9XeYPu6r5W9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configs = {\n",
        "    \"code_vector_size\": 0,\n",
        "    \"num_code_vector_groups\": 0,\n",
        "    \"num_code_vectors_per_group\": 0,\n",
        "    \"mask_time_prob\": 0,\n",
        "    \"num_mask_time_steps\": 0,\n",
        "    \"extracted_feature_size\": 0,\n",
        "    \"encoder_hidden_size\": 0,\n",
        "    \"gumbel_init_temperature\": 0,\n",
        "    \"contrastive_loss_temperature\": 0,\n",
        "    \"num_contrastive_loss_negative_samples\": 0,\n",
        "    \"loss_alpha\": 0\n",
        "}"
      ],
      "metadata": {
        "id": "LdHIHWdd5ubn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GumbelVectorQuantizer"
      ],
      "metadata": {
        "id": "VE9t6P5W43wQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GumbelVectorQuantizer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.num_groups = config[\"num_code_vector_groups\"]\n",
        "        self.num_vectors = config[\"num_code_vectors_per_group\"]\n",
        "\n",
        "        self.linear = nn.Linear(\n",
        "            config[\"extracted_feature_size\"],\n",
        "            self.num_groups * self.num_vectors\n",
        "        )\n",
        "        self.code_book = nn.Parameter(\n",
        "            torch.FloatTensor(1, self.num_groups, self.num_vectors, config[\"code_vector_size\"] // self.num_groups)\n",
        "        )\n",
        "\n",
        "        self.temperature = config[\"gumbel_init_temperature\"]\n",
        "\n",
        "    @staticmethod\n",
        "    def _compute_perplexity(probs: torch.Tensor, lengths: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            probs (torch.Tensor): with shape `(B, L, G, V)`\n",
        "            lengths (torch.Tensor): with shape `(B)`\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor with shape `(G, V)`\n",
        "        \"\"\"\n",
        "        where_calculate_probs = torch.arange(probs.size(1), device=probs.device).unsqueeze(0) < lengths.unsqueeze(-1)\n",
        "        probs = probs[where_calculate_probs == 1]\n",
        "\n",
        "        num_values = probs.size(0)\n",
        "        perplexity = probs.sum(0) / num_values\n",
        "\n",
        "        return perplexity\n",
        "\n",
        "    def forward(self, hidden_states: torch.Tensor, lengths: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hidden_states (torch.Tensor): with shape `(B, L, D1)`\n",
        "            lengths (torch.Tensor): with shape `(B)`\n",
        "\n",
        "        Returns:\n",
        "            tuple(\n",
        "            code_vectors (torch.Tensor): with shape `(B, L, D2)`\n",
        "            perplexity (torch.Tensor): with shape `(G, V)`\n",
        "            )\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size, length, _ = hidden_states.shape\n",
        "\n",
        "        hidden_states = self.linear(hidden_states)\n",
        "        # `(B, L, G * V)` -> `(B * L * G, V)`\n",
        "        hidden_states = hidden_states.view(batch_size * length * self.num_groups, -1)\n",
        "\n",
        "        code_vector_probs = nn.functional.gumbel_softmax(\n",
        "            hidden_states.float(), tau=self.temperature, hard=True\n",
        "        ).type_as(hidden_states)\n",
        "        code_vector_soft_dist = torch.softmax(\n",
        "            hidden_states.view(batch_size, length, self.num_groups, -1).float(), dim=-1\n",
        "        )\n",
        "        perplexity = self._compute_perplexity(code_vector_soft_dist, lengths)\n",
        "\n",
        "        code_vector_probs = code_vector_probs.view(batch_size * length, self.num_groups, -1).unsqueeze(-1)\n",
        "\n",
        "        code_vectors = code_vector_probs * self.code_book\n",
        "        # `(B * L, G, V, D)` -> `(B, L, G * D)`\n",
        "        code_vectors = code_vectors.sum(-2).view(batch_size, length, -1)\n",
        "\n",
        "        return code_vectors, perplexity"
      ],
      "metadata": {
        "id": "ZPmN2uqr4GQm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}